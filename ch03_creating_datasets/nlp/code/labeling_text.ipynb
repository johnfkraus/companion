{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sefilipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import collections\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import tldextract\n",
    "import numpy as np\n",
    "#snorkel\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "# web\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "\n",
    "ABSTAIN = -1\n",
    "FAKE = 0\n",
    "REAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>statement</th>\n",
       "      <th>sources</th>\n",
       "      <th>paragraph_based_content</th>\n",
       "      <th>fullText_based_content</th>\n",
       "      <th>label_fnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3106</td>\n",
       "      <td>2011-01-25T06:00:00-05:00</td>\n",
       "      <td>Joe Wilkinson</td>\n",
       "      <td>A national organization says Georgia has one o...</td>\n",
       "      <td>['http://www.ajc.com/news/georgia-politics-ele...</td>\n",
       "      <td>['A coalition of government watchdog groups la...</td>\n",
       "      <td>A coalition of government watchdog groups last...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5655</td>\n",
       "      <td>2012-04-02T11:42:20-04:00</td>\n",
       "      <td>Rick Scott</td>\n",
       "      <td>Says Barack Obama's health care law \"will be t...</td>\n",
       "      <td>['http://www.youtube.com/watch?v=TaC0mKApf9Q&amp;f...</td>\n",
       "      <td>['As Supreme Court justices embarked on three ...</td>\n",
       "      <td>As Supreme Court justices embarked on three da...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3506</td>\n",
       "      <td>2011-04-01T09:49:05-04:00</td>\n",
       "      <td>J.D. Alexander</td>\n",
       "      <td>Says the Southwest Florida Water Management Di...</td>\n",
       "      <td>['http://www.tampabay.com/news/politics/gubern...</td>\n",
       "      <td>[\"Here's a new one: The Senate budget committe...</td>\n",
       "      <td>Here's a new one: The Senate budget committee ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                       date         speaker  \\\n",
       "0  3106  2011-01-25T06:00:00-05:00   Joe Wilkinson   \n",
       "1  5655  2012-04-02T11:42:20-04:00      Rick Scott   \n",
       "2  3506  2011-04-01T09:49:05-04:00  J.D. Alexander   \n",
       "\n",
       "                                           statement  \\\n",
       "0  A national organization says Georgia has one o...   \n",
       "1  Says Barack Obama's health care law \"will be t...   \n",
       "2  Says the Southwest Florida Water Management Di...   \n",
       "\n",
       "                                             sources  \\\n",
       "0  ['http://www.ajc.com/news/georgia-politics-ele...   \n",
       "1  ['http://www.youtube.com/watch?v=TaC0mKApf9Q&f...   \n",
       "2  ['http://www.tampabay.com/news/politics/gubern...   \n",
       "\n",
       "                             paragraph_based_content  \\\n",
       "0  ['A coalition of government watchdog groups la...   \n",
       "1  ['As Supreme Court justices embarked on three ...   \n",
       "2  [\"Here's a new one: The Senate budget committe...   \n",
       "\n",
       "                              fullText_based_content label_fnn  \n",
       "0  A coalition of government watchdog groups last...      fake  \n",
       "1  As Supreme Court justices embarked on three da...      fake  \n",
       "2  Here's a new one: The Senate budget committee ...      fake  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'..\\data\\FNID-dataset\\dataset\\fake news detection(FakeNewsNet)\\fnn_train.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15212, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the label to numbers, to use it for the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label_numeric\"] = data.apply(lambda row: 1 if row[\"label_fnn\"]=='real' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the sentiment analysis package, to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriving the labels or valuable information from each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contacts a url, downloads the website's content and parses it.  \n",
    "def get_parsed_html(url):\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    parsed_html = BeautifulSoup(webpage)\n",
    "    return parsed_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.politifact.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poitifact_image_alt(url):\n",
    "    result = \"abstain\"\n",
    "    try:\n",
    "        parsed_html = get_parsed_html(url)\n",
    "        div = parsed_html.body.find('div', attrs={'class':'m-statement__meter'})\n",
    "        result = div.find(\"img\", attrs={'class':'c-image__original'})[\"alt\"]\n",
    "        time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.snopes.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snopes_image_alt(url):\n",
    "    result = \"abstain\"\n",
    "    try:\n",
    "        parsed_html = get_parsed_html(url)\n",
    "        div = parsed_html.body.find('div', attrs={'class':'media rating'})\n",
    "        result = div.find(\"img\")[\"alt\"]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.factcheck.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factcheck_first_paragraph(url):\n",
    "    result = \"abstain\"\n",
    "    try:\n",
    "        parsed_html = get_parsed_html(url)\n",
    "        div = parsed_html.body.find('div', attrs={'class':'entry-content'})\n",
    "        # if the first paragraph starts with 'Q:' and the second with 'A:' than it is a Q & A style; \n",
    "        # take the second paragraph\n",
    "        # otherwise take the first.\n",
    "        parag = div.find_all(\"p\")\n",
    "        if(parag[0].text[0:3] == 'Q: ' and parag[1].text[0:3] == 'A: '):           \n",
    "            return parag[1].text\n",
    "        return parag[0].text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.factcheck.afp.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factcheck_afp_title(url):\n",
    "    result = \"abstain\"\n",
    "    try:\n",
    "        parsed_html = get_parsed_html(url)\n",
    "        h3 = parsed_html.body.find('h3')\n",
    "        return h3.text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.twitter.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_twitter_name(url):\n",
    "    start = url.find('https')\n",
    "    sub = url[20+start:len(url)] # removing 'https://twitter.com/'\n",
    "    index = sub.find('/')\n",
    "    if(index == -1):\n",
    "        return sub\n",
    "    else:\n",
    "        return sub[:index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving urls of fact checking sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_checking_sites = {\n",
    "    \"www.politifact.com\" : get_poitifact_image_alt,\n",
    "    \"www.snopes.com\": get_snopes_image_alt,\n",
    "    \"www.twitter.com\":  extract_twitter_name,\n",
    "    \"www.factcheck.org\": get_factcheck_first_paragraph,\n",
    "    \"factcheck.afp.com\": get_factcheck_afp_title,\n",
    "    \"www.washingtonpost.com/news/fact-checker/\": None,\n",
    "    \"www.realclearpolitics.com\": None,\n",
    "    \"www.glennbeck.com\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sources_as_list(source, domain):\n",
    "    urls = source[1:-1].split(',')\n",
    "    u = []\n",
    "    for url in urls:\n",
    "        if domain in url:\n",
    "            u.append(url)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the new columns\n",
    "for site in fact_checking_sites: \n",
    "      data[site] = None\n",
    "data_size = data.shape[0]\n",
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_checking_sites_results = {\n",
    "    \"www.politifact.com\" : [None] * data_size,\n",
    "    \"www.snopes.com\": [None] * data_size,\n",
    "    \"www.twitter.com\":  [None] * data_size,\n",
    "    \"www.factcheck.org\": [None] * data_size,\n",
    "    \"factcheck.afp.com\": [None] * data_size,\n",
    "    \"www.washingtonpost.com/news/fact-checker/\": [None] * data_size,\n",
    "    \"www.realclearpolitics.com\": [None] * data_size,\n",
    "    \"www.glennbeck.com\": [None] * data_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the records\n",
    "# and looks through the sources for each fact-checking site\n",
    "#\n",
    "# Commented out because it takes hours to run (the sites will throttle too many requests)\n",
    "# the results are presented below.\n",
    "''' \n",
    "with open(\"factchecking_results.txt\", \"a\") as results:\n",
    "    for i, row in data.iterrows():\n",
    "        for site in fact_checking_sites: \n",
    "            sources = sources_as_list(row[\"sources\"], site)\n",
    "            if len(sources) != 0:\n",
    "                #print(\"{}\".format(i))\n",
    "                labels = \"\"\n",
    "                for source in sources:\n",
    "                    handler = fact_checking_sites[site]\n",
    "                    if handler:\n",
    "                        #print(\"Handling: {} ++++++++++++++++++++++++++\".format(site))\n",
    "                        source = str(source).strip()[1:-1]\n",
    "                        if(len(labels) > 0):\n",
    "                            labels += \", \"+handler(str(source))\n",
    "                        else:\n",
    "                            labels += handler(str(source))\n",
    "                        #print(\"Result: {} ++++++++++++++++++++++++++\".format(labels))\n",
    "                    else:\n",
    "                        if(len(labels) > 0):\n",
    "                            #print(\"Handling: {} ++++++++++++++++++++++++++\".format(site))\n",
    "                            labels += \", \"+ source\n",
    "                        else:\n",
    "                            labels += source\n",
    "                    #print(\"Result: {} ++++++++++++++++++++++++++\".format(labels))\n",
    "                fact_checking_sites_results[site][i] =labels\n",
    "                print(\"{} | {} | {}\".format(i, site, labels))\n",
    "                results.write(\"{} | {} | {}\\n\".format(i, site, labels))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in fact_checking_sites: \n",
    "      data[site] = fact_checking_sites_results[site]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALTERNATIVE TO THE TWO CELL ABOVE, IF LOADING FROM THE FILE\n",
    "apiResultsFile = open(\"apiResults.txt\", \"r\", encoding='utf-8')\n",
    "for line in apiResultsFile:\n",
    "    try:\n",
    "        sr = line.split(\"|\")\n",
    "        row = int(sr[0].strip())\n",
    "        col = sr[1].strip()\n",
    "        data.at[row,col] = sr[2]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "apiResultsFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowdsourcing - reading the results from the rated files, and adding them to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.glennbeck.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "glenbeck_ratings = pd.read_csv(r\"..\\data\\glennbeck_ratings.csv\");\n",
    "\n",
    "for i, row in glenbeck_ratings.iterrows():\n",
    "    data.loc[data[\"id\"] == row[\"id\"],[\"www.glennbeck.com\"]] = row[\"www.glennbeck.com\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.realclearpolitics.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_ratings = pd.read_csv(r\"..\\data\\realclearpolitics_ratings.csv\");\n",
    "\n",
    "for i, row in rp_ratings.iterrows():\n",
    "    data.loc[data[\"id\"] == row[\"id\"],[\"www.realclearpolitics.com\"]] = row[\"www.realclearpolitics.com\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### www.washingtonpost.com/news/fact-checker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_ratings = pd.read_csv(r\"..\\data\\washingtonpost_ratings.csv\");\n",
    "\n",
    "for i, row in wp_ratings.iterrows():\n",
    "    data.loc[data[\"id\"] == row[\"id\"],[\"www.washingtonpost.com/news/fact-checker/\"]] = row[\"www.washingtonpost.com/news/fact-checker/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the labels with Snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def label_snopes(row):\n",
    "    label = row[\"www.snopes.com\"]\n",
    "    if label is not None:\n",
    "        label = str(row[\"www.snopes.com\"])\n",
    "        if ('real' in label):\n",
    "            return REAL\n",
    "        else: \n",
    "            return FAKE\n",
    "    else: \n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def label_wp(row):\n",
    "    label = row[\"www.washingtonpost.com/news/fact-checker/\"]\n",
    "    if label is not None:\n",
    "        label = str(row[\"www.washingtonpost.com/news/fact-checker/\"])\n",
    "        if ('real' in label):\n",
    "            return REAL\n",
    "        else: \n",
    "            return FAKE\n",
    "    else: \n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def label_rp(row):\n",
    "    label = row[\"www.realclearpolitics.com\"]\n",
    "    if label is not None:\n",
    "        label = str(row[\"www.realclearpolitics.com\"])\n",
    "        if ('real' in label):\n",
    "            return REAL\n",
    "        else: \n",
    "            return FAKE\n",
    "    else: \n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_o_meter = {\n",
    "    \"true\": 4,\n",
    "    \"mostly-true\": 3,\n",
    "    \"half-true\": 2,\n",
    "    \"barely-true\": 1,\n",
    "    \"mostly-false\": -1,\n",
    "    \"false\": -2,\n",
    "    \"pants-fire\": -3    \n",
    "}\n",
    "@labeling_function()\n",
    "def label_politifact(row):\n",
    "    total_score = 0\n",
    "    labels = row[\"www.politifact.com\"]\n",
    "    #print(labels)\n",
    "    if(labels):\n",
    "        labels = str(row[\"www.politifact.com\"]).split(',')\n",
    "        # The last label has the newline character\n",
    "        if(len(labels) > 0):\n",
    "            labels[-1] = labels[-1][:-2]\n",
    "        for label in labels:\n",
    "            #print(label)\n",
    "            label = label.strip()\n",
    "            if(label in truth_o_meter):\n",
    "                total_score += truth_o_meter[label]                \n",
    "    #print(\"score: {} \".format(total_score))          \n",
    "    if(total_score > 0):\n",
    "        return REAL\n",
    "    if(total_score < 0): \n",
    "        return FAKE\n",
    "    \n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facktcheck_sentiment(row, columnName):\n",
    "    label = str(row[columnName])\n",
    "    score = 0\n",
    "    if(label):\n",
    "        claims = label[1:-1].split(',')\n",
    "        for claim in claims:\n",
    "            #print(claim)\n",
    "            sentiment = sid.polarity_scores(claim)\n",
    "            #print(sentiment)\n",
    "            if(sentiment[\"neg\"] > sentiment[\"pos\"]):\n",
    "                score -=1\n",
    "            elif(sentiment[\"pos\"] > sentiment[\"neg\"]):\n",
    "                score +=1\n",
    "        if(score > 0):\n",
    "            return REAL\n",
    "        elif (score < 0):\n",
    "            return FAKE\n",
    "        else:\n",
    "            return ABSTAIN\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def facktcheckqa_sentiment(row):\n",
    "    return facktcheck_sentiment(row, \"www.factcheck.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def facktcheckafpqa_sentiment(row):\n",
    "    return facktcheck_sentiment(row, \"factcheck.afp.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning from the liar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>statement</th>\n",
       "      <th>sources</th>\n",
       "      <th>paragraph_based_content</th>\n",
       "      <th>fullText_based_content</th>\n",
       "      <th>label-liar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18178</td>\n",
       "      <td>2020-03-18T13:26:42-04:00</td>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>\"COVID-19 started because we eat animals.\"</td>\n",
       "      <td>['https://www.cdc.gov/coronavirus/2019-ncov/ca...</td>\n",
       "      <td>['Vegan Instagram users are pinning the 2019 c...</td>\n",
       "      <td>Vegan Instagram users are pinning the 2019 cor...</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3350</td>\n",
       "      <td>2011-03-04T09:12:59-05:00</td>\n",
       "      <td>Glenn Beck</td>\n",
       "      <td>Says Michelle Obama has 43 people on her staff...</td>\n",
       "      <td>['http://www.glennbeck.com/2011/02/25/while-wo...</td>\n",
       "      <td>['Glenn Beck rekindled a falsehood about the s...</td>\n",
       "      <td>Glenn Beck rekindled a falsehood about the siz...</td>\n",
       "      <td>pants-fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14343</td>\n",
       "      <td>2017-07-21T11:52:44-04:00</td>\n",
       "      <td>Mike Pence</td>\n",
       "      <td>Says President Donald Trump \"has signed more l...</td>\n",
       "      <td>['https://nrf.com/events/retail-advocates-summ...</td>\n",
       "      <td>['Vice President Mike Pence says that when it ...</td>\n",
       "      <td>Vice President Mike Pence says that when it co...</td>\n",
       "      <td>half-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                       date          speaker  \\\n",
       "0  18178  2020-03-18T13:26:42-04:00  Instagram posts   \n",
       "1   3350  2011-03-04T09:12:59-05:00       Glenn Beck   \n",
       "2  14343  2017-07-21T11:52:44-04:00       Mike Pence   \n",
       "\n",
       "                                           statement  \\\n",
       "0         \"COVID-19 started because we eat animals.\"   \n",
       "1  Says Michelle Obama has 43 people on her staff...   \n",
       "2  Says President Donald Trump \"has signed more l...   \n",
       "\n",
       "                                             sources  \\\n",
       "0  ['https://www.cdc.gov/coronavirus/2019-ncov/ca...   \n",
       "1  ['http://www.glennbeck.com/2011/02/25/while-wo...   \n",
       "2  ['https://nrf.com/events/retail-advocates-summ...   \n",
       "\n",
       "                             paragraph_based_content  \\\n",
       "0  ['Vegan Instagram users are pinning the 2019 c...   \n",
       "1  ['Glenn Beck rekindled a falsehood about the s...   \n",
       "2  ['Vice President Mike Pence says that when it ...   \n",
       "\n",
       "                              fullText_based_content   label-liar  \n",
       "0  Vegan Instagram users are pinning the 2019 cor...  barely-true  \n",
       "1  Glenn Beck rekindled a falsehood about the siz...   pants-fire  \n",
       "2  Vice President Mike Pence says that when it co...    half-true  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Liar dataset\n",
    "liar = pd.read_csv(r'..\\data\\FNID-dataset\\dataset\\fake news detection(LIAR)\\liar_train.csv')\n",
    "liar.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['barely-true', 'pants-fire', 'half-true', 'mostly-true', 'true',\n",
       "       'false'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the unique labels\n",
    "labels = liar[\"label-liar\"].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "# true speakers\n",
    "counts_true = collections.Counter(liar[(liar[\"label-liar\"]==\"mostly-true\") | (liar[\"label-liar\"]==\"true\")][\"speaker\"])\n",
    "counts_true = dict(counts_true.most_common())\n",
    "# false speakers\n",
    "counts_false = collections.Counter(liar[(liar[\"label-liar\"]==\"false\" )| (liar[\"label-liar\"]==\"pants-fire\")][\"speaker\"])\n",
    "counts_false = dict(counts_false.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_percent = {}\n",
    "for k, v in counts_false.items():\n",
    "    total = v\n",
    "    if k in counts_true:\n",
    "        total += counts_true[k]\n",
    "    false_percent[k] = v/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_percent = {}\n",
    "for k, v in counts_true.items():\n",
    "    total = v\n",
    "    if k in counts_false:\n",
    "        total += counts_false[k]\n",
    "    true_percent[k] = v/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def speaker(row):\n",
    "    speaker = row[\"speaker\"]\n",
    "    if(speaker in true_percent and true_percent[speaker] > 0.6):\n",
    "        return REAL\n",
    "    if(speaker in false_percent and false_percent[speaker] > 0.6):\n",
    "        return FAKE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the snorkel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12170/12170 [00:01<00:00, 8529.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label_rp</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_wp</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>0.003122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_snopes</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.027691</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.004108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_politifact</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.244618</td>\n",
       "      <td>0.184717</td>\n",
       "      <td>0.071076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facktcheckqa_sentiment</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.019967</td>\n",
       "      <td>0.010682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facktcheckafpqa_sentiment</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <td>6</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.721282</td>\n",
       "      <td>0.216270</td>\n",
       "      <td>0.075678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts\n",
       "label_rp                   0   [0, 1]  0.007970  0.006984   0.002219\n",
       "label_wp                   1   [0, 1]  0.009860  0.008874   0.003122\n",
       "label_snopes               2      [0]  0.027691  0.026952   0.004108\n",
       "label_politifact           3   [0, 1]  0.244618  0.184717   0.071076\n",
       "facktcheckqa_sentiment     4   [0, 1]  0.020707  0.019967   0.010682\n",
       "facktcheckafpqa_sentiment  5   [0, 1]  0.000822  0.000822   0.000493\n",
       "speaker                    6   [0, 1]  0.721282  0.216270   0.075678"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac = 1, random_state=1)\n",
    "df_train = data[:12170]\n",
    "df_valid = data[12170:]\n",
    "\n",
    "lfs = [\n",
    "        label_rp,\n",
    "        label_wp, \n",
    "        label_snopes,\n",
    "        label_politifact,\n",
    "        facktcheckqa_sentiment,\n",
    "        facktcheckafpqa_sentiment,\n",
    "        speaker\n",
    "      ]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MajorityLabelVoter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b82883125ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmajority_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMajorityLabelVoter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpreds_train_majority\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmajority_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mL_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mY_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label_numeric\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MajorityLabelVoter' is not defined"
     ]
    }
   ],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "preds_train_majority = majority_model.predict(L=L_train)\n",
    "L_valid = applier.apply(df=df_valid)\n",
    "\n",
    "Y_valid = df_valid[\"label_numeric\"].values\n",
    "LFAnalysis(L_valid, lfs).lf_summary(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0768b427894c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlabel_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_train_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreds_valid_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mL_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\snorkel\\labeling\\model\\label_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, L_train, Y_dev, class_balance, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_constants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_shift\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_class_balance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_balance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m         \u001b[0mlf_analysis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLFAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlf_analysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlf_coverages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\snorkel\\labeling\\model\\label_model.py\u001b[0m in \u001b[0;36m_create_tree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_clique_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\snorkel\\labeling\\model\\graph_utils.py\u001b[0m in \u001b[0;36mget_clique_tree\u001b[1;34m(nodes, edges)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"members\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"members\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "label_model = LabelModel()\n",
    "label_model.fit(L_train=L_train, n_epochs=100, log_freq=100, seed=123)\n",
    "preds_train_label = label_model.predict(L=L_train)\n",
    "preds_valid_label = label_model.predict(L=L_valid)\n",
    "L_valid = applier.apply(df_valid)\n",
    "\n",
    "Y_valid = df_valid[\"label_numeric\"].values\n",
    "f1_micro = label_model.score(L_valid, Y_valid, metrics=[\"f1_micro\"])\n",
    "accuracy = label_model.score(L_valid, Y_valid, metrics=[\"accuracy\"])\n",
    "recall = label_model.score(L_valid, Y_valid, metrics=[\"recall\"])\n",
    "precision = label_model.score(L_valid, Y_valid, metrics=[\"precision\"])\n",
    "\n",
    "print(\"{} {} {} {}\".format(f1_micro, accuracy, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 0.7560199909132213} {'accuracy': 0.7560199909132213} {'recall': 0.8211091234347049} {'precision': 0.7314741035856573}\n"
     ]
    }
   ],
   "source": [
    "Y_valid = df_valid[\"label_numeric\"].values\n",
    "f1_micro = majority_model.score(L_valid, Y_valid, metrics=[\"f1_micro\"])\n",
    "accuracy = majority_model.score(L_valid, Y_valid, metrics=[\"accuracy\"])\n",
    "recall = majority_model.score(L_valid, Y_valid, metrics=[\"recall\"])\n",
    "precision = majority_model.score(L_valid, Y_valid, metrics=[\"precision\"])\n",
    "\n",
    "print(\"{} {} {} {}\".format(f1_micro, accuracy, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_train_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-629de5854ed4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msnorkel_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_train_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds_valid_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msnorkel_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preds_train_label' is not defined"
     ]
    }
   ],
   "source": [
    "snorkel_predictions = np.concatenate((preds_train_label,preds_valid_label))\n",
    "snorkel_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"snorkel_labels\"] =snorkel_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_nlp.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
